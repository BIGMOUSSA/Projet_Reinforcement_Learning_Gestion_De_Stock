{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrNcVZ9j4za2"
      },
      "outputs": [],
      "source": [
        "#!pip install stable_baselines3\n",
        "#!pip install tensorflow\n",
        "#!pip install stable-baselines\n",
        "#!pip install gym\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9yKcH1Ba2VxR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rbInQDa55ccL"
      },
      "outputs": [],
      "source": [
        "class TradingEnv(Env):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.balance = 10000\n",
        "        self.net_worth = []\n",
        "\n",
        "        # Dimensions des espaces d'observations et d'actions\n",
        "        self.observation_space = Box(low=0, high=np.inf, shape=(6,))\n",
        "        self.action_space = Discrete(3)\n",
        "\n",
        "        # Episode\n",
        "        self._start_tick = 0\n",
        "        self._end_tick = len(df) - 1\n",
        "        self._done = False\n",
        "        self._current_tick = 0\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        # Réinitialiser l'environnement\n",
        "        self._current_tick = self._start_tick\n",
        "        self._done = False\n",
        "        self.balance = 10000\n",
        "        self.net_worth = [self.balance]\n",
        "        self.position = 0\n",
        "\n",
        "        return self._get_observation()\n",
        "\n",
        "    def step(self, action):\n",
        "       # Actions: 0=Acheter, 1=Vendre, 2=Rien faire\n",
        "\n",
        "       current_price = self._get_current_close()\n",
        "\n",
        "       if action == 0:\n",
        "           # Acheter\n",
        "           qty = 1000 // current_price\n",
        "           self.balance -= qty * current_price\n",
        "           self.position += qty\n",
        "       elif action == 1:\n",
        "           # Vendre\n",
        "           qty = min(abs(self.position), 1000 // current_price)\n",
        "           self.balance += qty * current_price\n",
        "           self.position -= qty\n",
        "\n",
        "       # Calculer reward\n",
        "       self.net_worth.append(self.balance + self.position * current_price)\n",
        "       reward = self.net_worth[-1] - self.net_worth[-2]\n",
        "\n",
        "       # MAJ état\n",
        "       self._current_tick += 1\n",
        "       self._done = self._current_tick == self._end_tick\n",
        "\n",
        "       return self._get_observation(), reward, self._done, {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        obs = np.array([\n",
        "            self.balance,\n",
        "            self.position,\n",
        "            self._get_current_open(),\n",
        "            self._get_current_high(),\n",
        "            self._get_current_low(),\n",
        "            self._get_current_close()\n",
        "        ])\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def _get_current_close(self):\n",
        "        return self.df.loc[self._current_tick, 'Close']\n",
        "\n",
        "    def _get_current_open(self):\n",
        "        return self.df.loc[self._current_tick, 'Open']\n",
        "\n",
        "    def _get_current_high(self):\n",
        "        return self.df.loc[self._current_tick, 'High']\n",
        "\n",
        "    def _get_current_low(self):\n",
        "        return self.df.loc[self._current_tick, 'Low']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w2l6dnAN_itZ"
      },
      "outputs": [],
      "source": [
        "class TradingQAgent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.lr = 0.1\n",
        "        self.gamma = 0.95\n",
        "        self.eps = 1.0\n",
        "        self.decay = 0.99995\n",
        "        self.q_table = pd.DataFrame(columns=list(range(env.action_space.n)),\n",
        "                                    dtype=np.float64)\n",
        "\n",
        "    def train(self, episodes):\n",
        "        for e in range(episodes):\n",
        "            state = self.env.reset()\n",
        "            done = False\n",
        "            score = 0\n",
        "\n",
        "            while not done:\n",
        "                action = self.get_action(state)\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "                self.update_qtable(state, action, reward, next_state)\n",
        "\n",
        "                state = next_state\n",
        "                score += reward\n",
        "\n",
        "            self.eps = max(0.01, self.eps*self.decay)\n",
        "            print(\"Episode {} Score {}\".format(e,score))\n",
        "\n",
        "\n",
        "    def get_action(self, state):\n",
        "        if np.random.random() < self.eps:\n",
        "            return self.env.action_space.sample()\n",
        "        else:\n",
        "            return np.argmax(self.q_table.loc[tuple(state)])\n",
        "\n",
        "\n",
        "    def update_qtable(self, state, action, reward, next_state):\n",
        "        q_1 = self.q_table.loc[tuple(state)][action]\n",
        "        q_2 = reward + self.gamma*max(self.q_table.loc[tuple(next_state)])\n",
        "        self.q_table.loc[tuple(state)][action] += self.lr*(q_2 - q_1)\n",
        "\n",
        "    def test(self, episodes):\n",
        "        for e in range(episodes):\n",
        "            done = False\n",
        "            score = 0\n",
        "            state = self.env.reset()\n",
        "\n",
        "            while not done:\n",
        "                action = np.argmax(self.q_table.loc[tuple(state)])\n",
        "                state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "                score += reward\n",
        "\n",
        "            print(\"Test {} Score {}\".format(e, score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2LSBtEdNZm4E",
        "outputId": "2a376256-d55d-4453-c79d-a3301f36a5f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001-01-02</td>\n",
              "      <td>1320.280029</td>\n",
              "      <td>1320.280029</td>\n",
              "      <td>1276.050049</td>\n",
              "      <td>1283.270020</td>\n",
              "      <td>1129400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001-01-03</td>\n",
              "      <td>1283.270020</td>\n",
              "      <td>1347.760010</td>\n",
              "      <td>1274.619995</td>\n",
              "      <td>1347.560059</td>\n",
              "      <td>1880700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001-01-04</td>\n",
              "      <td>1347.560059</td>\n",
              "      <td>1350.239990</td>\n",
              "      <td>1329.140015</td>\n",
              "      <td>1333.339966</td>\n",
              "      <td>2131000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001-01-05</td>\n",
              "      <td>1333.339966</td>\n",
              "      <td>1334.770020</td>\n",
              "      <td>1294.949951</td>\n",
              "      <td>1298.349976</td>\n",
              "      <td>1430800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001-01-08</td>\n",
              "      <td>1298.349976</td>\n",
              "      <td>1298.349976</td>\n",
              "      <td>1276.290039</td>\n",
              "      <td>1295.859985</td>\n",
              "      <td>1115500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date         Open         High          Low        Close      Volume\n",
              "0  2001-01-02  1320.280029  1320.280029  1276.050049  1283.270020  1129400000\n",
              "1  2001-01-03  1283.270020  1347.760010  1274.619995  1347.560059  1880700000\n",
              "2  2001-01-04  1347.560059  1350.239990  1329.140015  1333.339966  2131000000\n",
              "3  2001-01-05  1333.339966  1334.770020  1294.949951  1298.349976  1430800000\n",
              "4  2001-01-08  1298.349976  1298.349976  1276.290039  1295.859985  1115500000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Charger les données\n",
        "data = pd.read_csv('cleaned_data/Training.csv')\n",
        "data.drop(columns={'Unnamed: 0'}, inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "bOqXRLA-_oZB",
        "outputId": "1f988d66-af39-4f36-e398-a2e8d6f58663"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'env' from 'env' (c:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\REINFORCEMENT_LEARNING\\Projet_Reinforcement_Learning_Gestion_De_Stock\\env.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\REINFORCEMENT_LEARNING\\Projet_Reinforcement_Learning_Gestion_De_Stock\\RL_Project.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ANSD/OneDrive%20-%20Azubi%20Africa/master/DIT/M2/REINFORCEMENT_LEARNING/Projet_Reinforcement_Learning_Gestion_De_Stock/RL_Project.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39menv\u001b[39;00m \u001b[39mimport\u001b[39;00m env\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ANSD/OneDrive%20-%20Azubi%20Africa/master/DIT/M2/REINFORCEMENT_LEARNING/Projet_Reinforcement_Learning_Gestion_De_Stock/RL_Project.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m agent \u001b[39m=\u001b[39m TradingQAgent(env)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ANSD/OneDrive%20-%20Azubi%20Africa/master/DIT/M2/REINFORCEMENT_LEARNING/Projet_Reinforcement_Learning_Gestion_De_Stock/RL_Project.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m agent\u001b[39m.\u001b[39mtrain(\u001b[39m100\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'env' from 'env' (c:\\Users\\ANSD\\OneDrive - Azubi Africa\\master\\DIT\\M2\\REINFORCEMENT_LEARNING\\Projet_Reinforcement_Learning_Gestion_De_Stock\\env.py)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from env import TradingEnv\n",
        "from agent import TradingQAgent\n",
        "agent = TradingQAgent(env)\n",
        "agent.train(100)\n",
        "agent.test(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
